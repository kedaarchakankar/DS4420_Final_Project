---
title: "mlp_manual"
author: "Jonathan Hong"
date: "2025-12-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Read in Data

```{r data}
# read in data (preprocessed already)
y_train <- read.csv('y_train.csv')
y_test <- read.csv('y_test.csv')
X_train <- read.csv('features_train.csv')
X_test <- read.csv('features_test.csv')

# add bias terms to features (optional)


# remove index columns and convert y to vectors
X_train <- X_train[,2:7]
X_test <- X_test[, 2:7]
y_train <- y_train$VitaminC
y_test <- y_test$VitaminC

head(X_train)
```

## Define activation functions

```{r functions, echo=FALSE}
# ReLU function
relu <- function(x) {
  matrix(pmax(0, x))
}

# post-activation function (to make the forward and backward pass smoother)
h <- function(w, x) { # w is weight matrix, x is input
  return(relu(t(w) %*% x))
}

# prediction function (relu on output)
f <- function(x,w1,w2,w3){
  h1 <- relu(t(w1) %*% x)
  h2 <- relu(t(w2) %*% h1)
  return(relu(t(w3) %*% h2))
}
```

## Neural Network Anatomy

Input: 6 features -> 6x1 vector
First layer: 12 nodes
Second layer: 5 nodes
Output: 1 scalar value

Objective function: Mean Squared Error (MSE)

Weights:
W1: 6x12 matrix
W2: 12x5 matrix
W3: 5x1 vector

```{r setup}
# initialize weights
W1 <- matrix(rnorm(6*12), nrow=6, ncol=12)
W2 <- matrix(rnorm(12*5), nrow=12, ncol=5)
W3 <- matrix(rnorm(5*1), nrow=5, ncol=1)

# set up other parameters
step <- 0.1
runs <- 1000
n <- nrow(X_train)

# test functions
?matrix
x <- t(as.matrix(X_train[i, ]))
h1 <- h(W1, x)
h2 <- h(W2, h1)
y_hat <- h(W3, h2)
```

## Run gradient descent
dL/dW3: (2/n)\sum((f(x) - y_i)) * (h2 * 1_{f(x)>0})
dL/dW2: (2/n)\sum((f(x) - y_i)) * (W3 * 1_{f(x)>0})(h1 * 1_{h2>0})^T
dL/dW1: (2/n)\sum((f(x) - y_i)) * (x * 1_{h1>0})((W3 * 1_{f(x)>0})^T(W2 * 1_{h2>0})^T)

```{r training, cache=TRUE}
# run gradient descent
errors <- numeric()

for (run in 1:runs) {
  # compute w3 derivative
  dW3 <- matrix(0, nrow=5, ncol=1)  # initialize empty w3 derivative matrix
  for (i in 1:n) {
    x <- t(as.matrix(X_train[i, ])) # only way i could get it to properly initialize column vector
    h1 <- h(W1, x) #12x1
    h2 <- h(W2, h1) #5x1
    y_hat <- h(W3, h2) #1x1
    mat <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # relu derivative, scalar, 1x1
    dW3 <- dW3 + ((2/n)*(f(x, W1, W2, W3) - y_train[i])[1]*(h2 * mat))  # sum up w3 derivative
  }
  
  
  # compute w2 derivative
  dW2 <- matrix(0, nrow=12, ncol=5)
  for (i in 1:n) {
    x <- t(as.matrix(X_train[i, ]))
    h1 <- h(W1, x) #12x1
    h2 <- h(W2, h1) #5x1
    y_hat <- h(W3, h2) #1x1
    mat1 <- ifelse(t(W2)%*%h1>0, 1, 0) #5x1
    mat2 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar #1x1
    dW2 <- dW2 + ((2/n)*(f(x, W1, W2, W3) - y_train[i])[1] * (W3 * mat2) %*% t(h1 * mat1)) # sum up w2 derivative, outer product at the end
  }
  
  
  # compute w1 derivative
  dW1 <- matrix(0, nrow=5, ncol=1)
  for (i in 1:n) {
    x <- t(as.matrix(X_train[i, ]))
    h1 <- h(W1, x)
    h2 <- h(W2, h1)
    y_hat <- h(W3, h2)
    mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
    mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
    mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
    dW1 <- dW1 + ((2/n*f(x, W1, W2, W3) - y_train[i])[1] * ((x * mat1) %*% (t(W3 * mat3) %*% t(W2 * mat2)))) # sum up w1 derivative, outer product
  }
  
  # update weights together
  W3 <- W3 - (step*dW3)
  W2 <- W2 - (step*dW2)
  W1 <- W1 - (step*dW1)
  
  # record error
  e <- (1/n) * sum((apply(X_train, MARGIN=1, FUN=f) - y)^2)
  errors <- c(errors, e)
}

```

```{r plots}
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
```