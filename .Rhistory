x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# initialize weights
W1 <- matrix(rnorm(6*12, sd=0.1), nrow=6, ncol=12)
W2 <- matrix(rnorm(12*5, sd=0.1), nrow=12, ncol=5)
W3 <- matrix(rnorm(5*1, sd=0.1), nrow=5, ncol=1)
# set up other parameters
step <- 0.7
runs <- 11
n <- nrow(X_train)
# initialize weights
W1 <- matrix(rnorm(6*12, sd=0.1), nrow=6, ncol=12)
W2 <- matrix(rnorm(12*5, sd=0.1), nrow=12, ncol=5)
W3 <- matrix(rnorm(5*1, sd=0.1), nrow=5, ncol=1)
# set up other parameters
step <- 0.7
runs <- 11
n <- nrow(X_train)
knitr::opts_chunk$set(echo = TRUE)
# run gradient descent
errors <- numeric()
for (run in 1:runs) {
# initialize weight derivatives
dW3 <- matrix(0, nrow=5, ncol=1)
dW2 <- matrix(0, nrow=12, ncol=5)
dW1 <- matrix(0, nrow=6, ncol=12)
loss_sum <- 0 # total loss for the run
# compute derivatives
for (i in 1:n) {
x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# initialize weights
W1 <- matrix(rnorm(6*12), nrow=6, ncol=12)
W2 <- matrix(rnorm(12*5), nrow=12, ncol=5)
W3 <- matrix(rnorm(5*1), nrow=5, ncol=1)
# set up other parameters
step <- 0.7
runs <- 20
n <- nrow(X_train)
knitr::opts_chunk$set(echo = TRUE)
# run gradient descent
errors <- numeric()
for (run in 1:runs) {
# initialize weight derivatives
dW3 <- matrix(0, nrow=5, ncol=1)
dW2 <- matrix(0, nrow=12, ncol=5)
dW1 <- matrix(0, nrow=6, ncol=12)
loss_sum <- 0 # total loss for the run
# compute derivatives
for (i in 1:n) {
x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# initialize weights
W1 <- matrix(rnorm(6*12), nrow=6, ncol=12)
W2 <- matrix(rnorm(12*5), nrow=12, ncol=5)
W3 <- matrix(rnorm(5*1), nrow=5, ncol=1)
# set up other parameters
step <- 0.2
runs <- 50
n <- nrow(X_train)
knitr::opts_chunk$set(echo = TRUE)
# run gradient descent
errors <- numeric()
for (run in 1:runs) {
# initialize weight derivatives
dW3 <- matrix(0, nrow=5, ncol=1)
dW2 <- matrix(0, nrow=12, ncol=5)
dW1 <- matrix(0, nrow=6, ncol=12)
loss_sum <- 0 # total loss for the run
# compute derivatives
for (i in 1:n) {
x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C")
plot(1:n_test, y_test, type="l")
knitr::opts_chunk$set(echo = TRUE)
# read in data (preprocessed already)
y_train <- read.csv('y_train.csv')
y_test <- read.csv('y_test.csv')
X_train <- read.csv('features_train.csv')
X_test <- read.csv('features_test.csv')
# add bias terms to features (optional)
# remove index columns and convert y to vectors
X_train <- X_train[,2:7]
X_test <- X_test[, 2:7]
y_train <- y_train$VitaminC
y_test <- y_test$VitaminC
head(X_train)
# ReLU function
relu <- function(x) {
matrix(pmax(0, x))
}
# post-activation function (to make the forward and backward pass smoother)
h <- function(w, x) { # w is weight matrix, x is input
return(relu(t(w) %*% x))
}
# prediction function (relu on output)
f <- function(x,w1,w2,w3){
h1 <- relu(t(w1) %*% x)
h2 <- relu(t(w2) %*% h1)
return(relu(t(w3) %*% h2))
}
# run gradient descent
errors <- numeric()
for (run in 1:runs) {
# initialize weight derivatives
dW3 <- matrix(0, nrow=5, ncol=1)
dW2 <- matrix(0, nrow=12, ncol=5)
dW1 <- matrix(0, nrow=6, ncol=12)
loss_sum <- 0 # total loss for the run
# compute derivatives
for (i in 1:n) {
x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C")
plot(1:n_test, y_test, type="l")
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend(legend=c("Predicted", "Actual"), col=c("blue", "red"))
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"))
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=c(0, max(y_pred)) col='blue')
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=c(0, max(y_pred)), col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"))
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=range(c(y_test, y_pred)), col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"))
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=range(c(y_test, y_pred)), col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"), lty=1, cex=0.8)
knitr::opts_chunk$set(echo = TRUE)
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=range(c(y_test, y_pred)), col='blue')
#lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"), lty=1, cex=0.8)
knitr::opts_chunk$set(echo = TRUE)
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
View(W1)
View(dW1)
knitr::opts_chunk$set(echo = TRUE)
# read in data (preprocessed already)
y_train <- read.csv('y_train.csv')
y_test <- read.csv('y_test.csv')
X_train <- read.csv('features_train.csv')
X_test <- read.csv('features_test.csv')
# add bias terms to features (optional)
# remove index columns and convert y to vectors
X_train <- X_train[,2:7]
X_test <- X_test[, 2:7]
y_train <- y_train$VitaminC
y_test <- y_test$VitaminC
head(X_train)
# ReLU function
relu <- function(x) {
matrix(pmax(0, x))
}
# post-activation function (to make the forward and backward pass smoother)
h <- function(w, x) { # w is weight matrix, x is input
return(relu(t(w) %*% x))
}
# prediction function (relu on output)
f <- function(x,w1,w2,w3){
h1 <- relu(t(w1) %*% x)
h2 <- relu(t(w2) %*% h1)
return(relu(t(w3) %*% h2))
}
# run gradient descent
errors <- numeric()
for (run in 1:runs) {
# initialize weight derivatives
dW3 <- matrix(0, nrow=5, ncol=1)
dW2 <- matrix(0, nrow=12, ncol=5)
dW1 <- matrix(0, nrow=6, ncol=12)
loss_sum <- 0 # total loss for the run
# compute derivatives
for (i in 1:n) {
x <- t(as.matrix(X_train[i, ]))
# single forward pass
y_hat <- f(x, W1, W2, W3)     # training output
loss <- y_hat - y_train[i]    # loss on that term
if (is.na(loss)) {
cat("NA in loss at i =", i, "\n")
cat("y_hat:", y_hat, "y_train[i]:", y_train[i], "\n")
break
}
loss_sum <- loss_sum + loss^2 # total loss for the run, updated with each loop
h1 <- h(W1, x)
h2 <- h(W2, h1)
mat1 <- ifelse(t(W1)%*%x>0, 1, 0)
mat2 <- ifelse(t(W2)%*%h1>0, 1, 0)
mat3 <- as.numeric(ifelse(t(W3)%*%h2>0, 1, 0)) # scalar
dfdw1 <- x %*% t((W2 %*% (W3 * mat2)) * mat1)
# sum up derivatives
dW3 <- dW3 + ((2/n)* loss[1] * (h2 * mat3))
dW2 <- dW2 + ((2/n)* loss[1] * mat3 * (kronecker(h1, t(W3 * mat2))))
dW1 <- dW1 + ((2/n) * loss[1] * mat3 * dfdw1)
}
# update weights together
W3 <- W3 - (step*dW3)
W2 <- W2 - (step*dW2)
W1 <- W1 - (step*dW1)
# record error
e <- loss_sum / n
errors <- c(errors, e)
# live update for each run
cat("Epoch", run, "Complete", "\n")
}
# predict on test set
y_pred <- c()
n_test <- nrow(X_test)
for(i in 1:n_test) {
x <- t(as.matrix(X_test[i, ]))
y_pred <- c(y_pred, f(x, W1, W2, W3))
}
# evaluate prediction accuracy
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred - y_test))
r2 <- 1 - (sum((y_test- y_pred)^2) / sum((y_test - mean(y_test))^2))
mse
rmse
mae
r2
# plot errors
plot(1:runs, errors, type = 'l', main='MSE over runs', xlab = 'Number of runs', ylab='Error')
# plot predictions vs. true values
plot(1:n_test, y_pred, type="l", ylab="Vitamin C", ylim=range(c(y_test, y_pred)), col='blue')
lines(1:n_test, y_test, type="l", col='red')
legend("topright", legend=c("Predicted", "Actual"), col=c("blue", "red"), lty=1, cex=0.8)
